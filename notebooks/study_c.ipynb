{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a586201d-912a-4293-ad64-fb46960dfb3b",
   "metadata": {},
   "source": [
    "## This notebook shows the full workflow for building models, simulating growth and obtaining SCFA predictions from data collected by the _ex vivo_ study conducted by Gurry et al. 2021 (Study C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160f9ad-82b0-425a-affe-af74a1e0ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "# import qiime2 as q2\n",
    "import micom as mm\n",
    "from micom.viz import plot_tradeoff\n",
    "from plotnine import *\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c83a66-2531-40fc-b0ed-c9e12e539e30",
   "metadata": {},
   "source": [
    "## First, we pull in the taxonomy table, matching each feature ID in the qiime2 output to a microbial taxa at the species level. We will build our models at the genus level, so collapse to this rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335aca8-c11d-431c-94b6-12326dc3df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/data/qiime2/taxonomy/data')\n",
    "taxa = pd.read_csv('taxonomy.tsv',sep='\\t') # read table\n",
    "taxa.set_index('Feature ID',inplace=True)\n",
    "taxa = taxa.Taxon.str.split(';',expand=True) # split ranks\n",
    "taxa = taxa.rename(columns = {0:'Kingdom',1:'Phylum',2:'Class',3:'Order',4:'Family',5:'Genus',6:'Species'})\n",
    "taxa = taxa.dropna(subset = ['Genus']) # drop undefined columns\n",
    "taxa = taxa.drop(columns = ['Species']) # drop species column\n",
    "taxa = taxa.apply(lambda column: column.str.split('_').str[2]) # remove prefixes\n",
    "taxa = (taxa.apply(lambda row: \";\".join(row.str.capitalize().fillna(\"\")), axis=1)\n",
    "        .to_frame().rename(columns = {0:'taxon'})) # join columns into taxon identifier\n",
    "taxa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e617ae1-e972-4cec-8ca4-7b6b3a4dfc6b",
   "metadata": {},
   "source": [
    "## Next we'll pull in the abundance table, with read counts for all present taxa. We'll drop those that aren't identified in the taxon list, and sum together duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a72aa5-10db-4fbf-80d6-6b825a9a791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/data/qiime2/')\n",
    "unrarefied_table = q2.Artifact.load('table.qza') # read table\n",
    "abundance = unrarefied_table.view(pd.DataFrame).reset_index().rename(columns = {'index':'sample_id'})\n",
    "to_drop = (abundance[abundance.columns[1:]].columns[~abundance[abundance.columns[1:]].\n",
    "                                                    columns.isin(taxa.index)].to_list()) # taxa to drop\n",
    "abundance = abundance.drop(columns = to_drop)\n",
    "abundance = abundance.rename(columns = taxa['taxon'].to_dict())\n",
    "\n",
    "abundance = pd.melt(abundance, id_vars = 'sample_id', value_vars = abundance.columns[:-1],\n",
    "                    var_name = 'id', value_name = 'abundance') # melt into long form df \n",
    "abundance = abundance.groupby(by = ['sample_id','id']).sum().reset_index()\n",
    "abundance['genus'] = abundance['id'].str.split(';').str[-1] # need a genus column in df \n",
    "abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd09f44-0488-4013-a28a-73ceea983b1b",
   "metadata": {},
   "source": [
    "## We also need a model database to pull our reconstructions from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce81ae-c0c7-41d3-900f-bb251e6a901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agora = ('/proj/gibbons/refs/micom_dbs/agora103_genus.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3aca59-13a9-4a49-8304-78e6a2756f8f",
   "metadata": {},
   "source": [
    "## Now, we'll build our models, with cutoff of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c841b-17d9-44f7-8140-2bd3dd010cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = mm.workflows.build(abundance,out_folder = '/proj/gibbons/nbohmann/exvivo/gurry1/micom/16S/16S_models_01/',\n",
    "                      model_db = agora, cutoff = 0.001, threads = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359421f5-0215-413c-b4d9-77f5267dfdcd",
   "metadata": {},
   "source": [
    "## Load in the carbon-stripped European Diet, and construct the intervention diets by augmenting with inulin and pectin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97172f5e-e989-47e0-8e14-8d4d7db38303",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/exvivo/diets')\n",
    "medium = pd.read_csv('european_agora_low_carb.csv')\n",
    "medium['flux'] = medium['flux']*.1\n",
    "os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/micom/16S/')\n",
    "manifest = pd.read_csv('16S_models/manifest.csv')\n",
    "pectin_medium = pd.concat([medium[~medium.reaction.str.contains('pect')], pd.DataFrame({'reaction':['EX_pect_m'],\n",
    "                                                                                        'flux':[0.75]})])\n",
    "inulin_medium = pd.concat([medium[~medium.reaction.str.contains('inulin')], pd.DataFrame({'reaction':['EX_inulin_m'],\n",
    "                                                                                          'flux':[10.5]})]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255e617-b2db-438c-82b3-686899478011",
   "metadata": {},
   "source": [
    "## Now we'll grow the samples using the respective media we constructed="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afb1a7-37cf-4e59-a853-50339b6336cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/micom/16S/')\n",
    "ctrl_growth = mm.workflows.grow(manifest, model_folder='16S_models',medium = medium, \n",
    "                                tradeoff = 0.7, strategy ='none', threads = 12)\n",
    "pectin_growth = mm.workflows.grow(manifest, model_folder='16S_models',medium = pectin_medium, \n",
    "                                    tradeoff = 0.7, strategy = 'none', threads = 12)\n",
    "inulin_growth = mm.workflows.grow(manifest, model_folder='16S_models/',medium = inulin_medium, \n",
    "                                   tradeoff = 0.7, strategy = 'none', threads = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124f106-c29a-4dd3-ae0e-d3b9d4e95e30",
   "metadata": {},
   "source": [
    "## This function will get the growth results from each sample, and filter down to butyrate, propionate and acetate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb9318-6976-43d3-98d2-43ef45a6d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fluxes(growth, cond):\n",
    "    growth = growth.exchanges\n",
    "    growth = growth[(growth.reaction.str.startswith('EX_but(e)'))|(growth.reaction.str.startswith('EX_ppa(e)'))|\n",
    "                    (growth.reaction.str.startswith('EX_ac(e)'))]\n",
    "    growth = growth[growth.direction == \"export\"].groupby([\"sample_id\", \"metabolite\", \"reaction\"]).apply(lambda df: sum(df.flux * df.abundance)).reset_index()\n",
    "    growth['index'] = growth['sample_id']+'_'+cond\n",
    "    return growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6800da-6e18-4a2d-9487-7cf4cbfdf1f8",
   "metadata": {},
   "source": [
    "## Now we'll concatenate a dataframe with all our growth results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a67c6-e3c1-4589-939c-dcf9b487ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame()\n",
    "predicted = pd.concat([predicted, get_fluxes(ctrl_growth, 'CTRL')])\n",
    "predicted = pd.concat([predicted, get_fluxes(inulin_growth, 'INUL')])\n",
    "predicted = pd.concat([predicted, get_fluxes(pectin_growth, 'PECT')])\n",
    "predicted = pd.pivot_table(predicted, index = 'index',columns = 'reaction', values = 0)\n",
    "but = predicted['EX_but(e)'].to_dict()\n",
    "ppa = predicted['EX_ppa(e)'].to_dict()\n",
    "ac = predicted['EX_ac(e)'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f7bd3-7a71-4fb3-ad0d-096e8edda858",
   "metadata": {},
   "source": [
    "## This function will calculate production rate from the experimental SCFA measurements, as well as standard deviations, and concatenate them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b56cf5-92a1-44db-abc4-8e68c8b19592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_calculate(arg):\n",
    "    os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/data/gc_data/normalized')\n",
    "    file = pd.read_csv(arg,index_col = 0)\n",
    "    file = file[['but','pro','ace']].dropna()\n",
    "    file = file[~file.index.str.contains(\"QC\")]\n",
    "    file['sample'] = file.index.str.split('-').str[0]\n",
    "    file['treatment'] = file.index.str.split('-').str[1]\n",
    "    file['timepoint'] = file.index.str.split('-').str[2]\n",
    "    file['replicate'] = file.index.str.split('-').str[4]\n",
    "    file = file.dropna()\n",
    "    baseline = file[file.timepoint.str.contains('0')]\n",
    "    baseline['treatment'] = 'INUL'\n",
    "    file = pd.concat([file,baseline])\n",
    "    baseline['treatment'] = 'PECT'\n",
    "    file = pd.concat([file,baseline])\n",
    "    file = file[(file.index.str.contains('CTRL'))|(file.index.str.contains('PECT'))\n",
    "                |(file.index.str.contains('INUL'))]\n",
    "    file = file[~file.timepoint.str.contains('0')]\n",
    "    file = file.sort_values(by=['sample','treatment','replicate','timepoint'])\n",
    "    file.set_index(['sample','treatment','replicate','timepoint'],inplace = True)\n",
    "    file = file.groupby(['sample','treatment','replicate']).diff().dropna().reset_index()\n",
    "    stdev = file.groupby(['sample','treatment']).std(numeric_only = True).reset_index().set_index('treatment')\n",
    "    file = file.groupby(['sample','treatment']).mean(numeric_only = True).reset_index()\n",
    "    file['but_dev'] = file['treatment'].map(stdev['but'].to_dict())\n",
    "    file['ppa_dev'] = file['treatment'].map(stdev['pro'].to_dict())\n",
    "    file['ace_dev'] = file['treatment'].map(stdev['ace'].to_dict())\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd94bdf-f314-40ee-aae8-1c55fc02f84a",
   "metadata": {},
   "source": [
    "## Now we can merge our predictions with the measured production rates for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c7d08-34b6-4cac-b46a-9163731ab885",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['H008-a.csv','H009-a.csv','H010-a.csv','H012-a.csv','H019-a.csv',\n",
    "               'H020-a.csv','H021-a.csv','H025-a.csv','H028-a.csv','H029-a.csv']\n",
    "os.chdir('/proj/gibbons/nbohmann/exvivo/gurry1/data/gc_data/normalized')\n",
    "flux = pd.DataFrame([])\n",
    "for x in tqdm(sample_list):\n",
    "    flux = pd.concat([flux,flux_calculate(x)])\n",
    "flux.reset_index(inplace = True,drop = True)\n",
    "flux['index'] = flux['sample']+'_'+flux['treatment']\n",
    "flux.set_index('index',inplace = True)\n",
    "flux['predicted_but'] = flux.index.map(but)\n",
    "flux['predicted_ac'] = flux.index.map(ac)\n",
    "flux['predicted_ppa'] = flux.index.map(ppa)\n",
    "flux = flux.dropna()\n",
    "flux['treatment'] = flux['treatment'].str.replace('CTRL','Control')\n",
    "flux['treatment'] = flux['treatment'].str.replace('INUL','Inulin')\n",
    "flux['treatment'] = flux['treatment'].str.replace('PECT','Pectin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ee99f-8245-402c-9c91-c25b1fbc69b7",
   "metadata": {},
   "source": [
    "## Finally, we'll plot predicted vs measured fluxes against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0ab53-d2b9-4548-8996-2e45156f99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1=(\n",
    "    ggplot(\n",
    "        flux[~flux.treatment.str.contains('FOS')],aes(x='pro',y='predicted_ppa'))\n",
    "        +geom_point(aes(color='treatment'),size=5)\n",
    "        +geom_smooth(method='lm',linetype='--')\n",
    "        +geom_errorbarh(aes(y =\"predicted_ppa\", xmin = flux['pro'] - flux['ppa_dev'],\n",
    "                            xmax=flux['pro'] + flux['ppa_dev']))\n",
    "        +scale_color_manual(values = ['deepskyblue','darksalmon', 'yellowgreen'])\n",
    "        +labs(title='Propionate',x='Measured($\\dfrac{mmol}{L*h}$)',\n",
    "              y = 'Predicted ($\\dfrac{mmol}{gDCW*h}$)')\n",
    "        +theme(text = element_text(size=20),panel_background=element_rect(fill = \"white\",\n",
    "                                colour = \"white\",size = 0.5, linetype = \"solid\"),\n",
    "                                panel_grid=element_line(size = .2, linetype = \"solid\",colour = \"gray\"),\n",
    "                                axis_line = element_line(size = 2, linetype = \"solid\",colour = \"black\"),\n",
    "                                legend_title=element_blank(),\n",
    "                                legend_position='right'))\n",
    "plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8c2c2-70dd-48a7-aaa6-f6ab386b5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2=(\n",
    "    ggplot(\n",
    "        flux[~flux.treatment.str.contains('FOS')],aes(x='but',y='predicted_but'))\n",
    "        +geom_point(aes(color='treatment'),size=5)\n",
    "        +geom_smooth(method='lm',linetype='--')\n",
    "        +scale_color_manual(values = ['deepskyblue','darksalmon', 'yellowgreen'])\n",
    "        +geom_errorbarh(aes(y =\"predicted_but\", xmin = flux['but'] - flux['but_dev'],\n",
    "                            xmax=flux['but'] + flux['but_dev']))\n",
    "        +labs(title='Butyrate',x='Measured ($\\dfrac{mmol}{L*h}$)',\n",
    "              y = 'Predicted ($\\dfrac{mmol}{gDCW*h}$)')\n",
    "        +theme(text = element_text(size=20),panel_background=element_rect(fill = \"white\",\n",
    "                                colour = \"white\",size = 0.5, linetype = \"solid\"),\n",
    "                                panel_grid=element_line(size = .2, linetype = \"solid\",colour = \"gray\"),\n",
    "                                axis_line = element_line(size = 2, linetype = \"solid\",colour = \"black\"),\n",
    "                                legend_title=element_blank(),\n",
    "                                legend_position='right'))\n",
    "plt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d4477-1b6d-4137-a0c2-25397a241f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt3=(\n",
    "    ggplot(\n",
    "        flux[~flux.treatment.str.contains('FOS')],aes(x='ace',y='predicted_ac'))\n",
    "        +geom_point(aes(color='treatment'),size=5)\n",
    "        +geom_smooth(method='lm',linetype='--')\n",
    "        +scale_color_manual(values = ['deepskyblue','darksalmon', 'yellowgreen'])\n",
    "        +geom_errorbarh(aes(y =\"predicted_ac\", xmin = flux['ace'] - flux['ace_dev'],\n",
    "                            xmax=flux['ace'] + flux['ace_dev']))\n",
    "        +labs(title='Acetate',x='Measured ($\\dfrac{mmol}{L*h}$)',\n",
    "              y = 'Predicted ($\\dfrac{mmol}{gDCW*h}$)')\n",
    "        +theme(text = element_text(size=20),panel_background=element_rect(fill = \"white\",\n",
    "                                colour = \"white\",size = 0.5, linetype = \"solid\"),\n",
    "                                panel_grid=element_line(size = .2, linetype = \"solid\",colour = \"gray\"),\n",
    "                                axis_line = element_line(size = 2, linetype = \"solid\",colour = \"black\"),\n",
    "                                legend_title=element_blank(),\n",
    "                                legend_position='right'))\n",
    "plt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee580a-9b43-486f-a4f1-6a3a38252a99",
   "metadata": {},
   "source": [
    "## Save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f753aae-02d4-4ecb-855c-def1964a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux.to_csv('/proj/gibbons/nbohmann/exvivo/scfa_paper/gurry1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
