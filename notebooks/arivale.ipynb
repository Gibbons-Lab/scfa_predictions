{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e763299-2834-41b6-ba4c-1a48c653e1f6",
   "metadata": {},
   "source": [
    "## We'll use this notebook to build and grow metabolic models for the Arivale cohort, and find associations between resulting SCFA production predictions and blood metabolites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e69fa-fc46-4b29-b560-cab505c01189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import micom\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import scipy\n",
    "import statsmodels\n",
    "from IPython.display import display\n",
    "from arivale_data_interface import *\n",
    "#below is some code for when you want to freeze your data. We have new samples coming in from trials, certain normalization\n",
    "#procedures change, etc. So this way you can work with consistent data using get_frozen_snapshot()\n",
    "frozen_ss_path='/proj/arivale/snapshots/arivale_snapshot_ISB_2020-03-16_2156/'\n",
    "sn=list_snapshot_contents()\n",
    "def get_frozen_snapshot(ss_name, ss_path=frozen_ss_path):\n",
    "    \n",
    "    return get_snapshot(ss_name, path=ss_path)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e19a8d-a539-42cd-ae68-6b850b9dd507",
   "metadata": {},
   "source": [
    "## First we'll pull in our medium. We'll use a functionally complete medium representing a European diet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364682a-b912-4315-9216-e12b3b96dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/exvivo/diets')\n",
    "diet = pd.read_csv('western_completed.csv')\n",
    "diet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bc9e2-16c2-419b-a06b-0b5d02b52a91",
   "metadata": {},
   "source": [
    "## Now we pull in our abundance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d3c3f-596d-4245-b501-866c957a98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance = pd.read_csv('/proj/arivale/microbiome/16S_processed/asvs.csv')\n",
    "abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf899dc-a2a3-4c85-8d75-d9a8fe5bf335",
   "metadata": {},
   "source": [
    "## To get taxonomy, we'll also grab the corresponding refseq taxonomy table, and map onto the abundance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138b4f2-b2a5-4041-ab2f-4f2cdb9cf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv('/proj/arivale/microbiome/16S_processed/taxonomy_refseq.csv')\n",
    "taxonomy['taxon'] = taxonomy[['Kingdom','Phylum','Class','Order','Family','Genus']].apply(lambda row: \".\".join(\n",
    "    row.fillna(\"\").str.lower()), axis=1).to_frame()\n",
    "taxonomy = taxonomy.set_index('id')['taxon'].to_dict()\n",
    "abundance['taxon'] = abundance['hash'].map(taxonomy)\n",
    "abundance['genus'] = abundance['taxon'].str.split('.').str[-1].str.capitalize()\n",
    "abundance['genus'] = abundance['genus'].replace('', np.nan)\n",
    "abundance = abundance.dropna()\n",
    "abundance.rename(columns = {'id':'sample_id'}, inplace = True)\n",
    "abundance = abundance.groupby(by = ['sample_id','genus'])['count'].agg('sum').reset_index()\n",
    "abundance['abundance'] = abundance['count']/abundance.groupby('sample_id')['count'].transform('sum')\n",
    "abundance['taxon'] = abundance['genus']\n",
    "abundance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922993ba-0eda-4d2b-9edc-b3a263f00b09",
   "metadata": {},
   "source": [
    "## Now we can build our models, using the AGORA (version 1.03) database. We'll use an abundance cutoff of 0.001 for consistency with previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecb733-949b-4981-9325-41eab94f8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "agora = ('/proj/gibbons/refs/micom_dbs/agora103_genus.qza')\n",
    "manifest = micom.workflows.build(abundance, agora, '/proj/gibbons/nbohmann/arivale/models_reclass', \n",
    "                                 cutoff = 0.001, threads = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2afae-52b2-4984-8adf-8f0cfa7f7cff",
   "metadata": {},
   "source": [
    "## We'll need a manifest file too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180a75d-e84f-44e8-806a-e76acb83cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/arivale/models_reclass')\n",
    "manifest = pd.DataFrame({'file':os.listdir()})\n",
    "manifest['sample_id']= manifest['file'].str.split('.').str[0]\n",
    "manifest = manifest[~manifest['file'].str.contains('manifest')]\n",
    "manifest.to_csv('manifest.csv')\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f4e0d-6864-4314-a296-7b75bf6d7be8",
   "metadata": {},
   "source": [
    "## Now we grow the models again, using the standard European diet and a tradeoff parameter of 0.7, for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650088a-d55c-4820-9b64-aee16d8a4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/proj/gibbons/nbohmann/arivale')\n",
    "growth = micom.workflows.grow(manifest, 'models_reclass', diet, tradeoff = 0.7,threads = 20)\n",
    "growth.growth_rates.to_csv('/proj/gibbons/nbohmann/arivale/reclass_growthrates.csv')\n",
    "growth.exchanges.to_csv('/proj/gibbons/nbohmann/arivale/reclass_exchanges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79703ee4-5745-4b28-a747-56f44c2911af",
   "metadata": {},
   "source": [
    "## We can scale the flux by abundance and pull out SCFA exchanges, pivoting the table for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a4c50-7b5b-485a-8bd2-accfb502d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = pd.read_csv('/proj/gibbons/nbohmann/arivale/reclass_exchanges.csv', index_col = 0)\n",
    "exchanges = exchanges[(exchanges.reaction.str.startswith('EX_but(e)'))|(exchanges.reaction.str.startswith('EX_ppa(e)')\n",
    "                                                                       |(exchanges.reaction.str.startswith('EX_ac(e)')))]\n",
    "exchanges = exchanges[exchanges.direction == \"export\"].groupby([\"sample_id\", \"metabolite\", \"reaction\"]).apply(\n",
    "    lambda df: sum(df.flux * df.abundance)).reset_index()\n",
    "exchanges = pd.pivot_table(exchanges, index = 'sample_id', columns = 'metabolite', values = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329541d-b424-4e6d-b7e6-a8fd1e1f5b7d",
   "metadata": {},
   "source": [
    "## Let's add a column for total SCFA production. We'll also fill in missing values and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f5913-8a41-4c58-92f5-e10b0de9271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges['Total'] = exchanges['but[e]'] + exchanges['ppa[e]'] + exchanges['ac[e]']\n",
    "exchanges['ButyrateAndPropionate'] = exchanges['but[e]'] + exchanges['ppa[e]']\n",
    "exchanges = exchanges.rename(columns = {'ac[e]':'Acetate','but[e]':'Butyrate','ppa[e]':'Propionate'})\n",
    "exchanges = exchanges.fillna(0.0)\n",
    "exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ef727-95f8-405d-b85d-404cd39dafe4",
   "metadata": {},
   "source": [
    "## We'll need metadata to merge with the growth data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d0e01-39e9-4e8d-a064-659199160a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('/proj/gibbons/arivale_16S/data/metadata.csv').rename(columns = {'id':'sample_id'})\n",
    "exchanges = pd.merge(exchanges, metadata, on = 'sample_id', how = 'inner')\n",
    "exchanges = exchanges.dropna(subset = 'days_in_program')\n",
    "exchanges = exchanges.sort_values(by = 'days_in_program')\n",
    "exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998289ab-809f-43a4-92be-b8acd0e0cf63",
   "metadata": {},
   "source": [
    "## Now we'll get our blood chemistry panel and z-score all the markers. Then we'll merge the chemistries with our predictions, using a tolerance of 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af772e-0f8b-42e1-bdb3-4db2bf587522",
   "metadata": {},
   "outputs": [],
   "source": [
    "chems = get_frozen_snapshot(\"chemistries\").sort_values(by = 'days_in_program') #get chemistries\n",
    "chem_features = chems.columns[12:]  # inspect the table to find out where the metadata ends \n",
    "for feature in chem_features: #zscore all the features\n",
    "    if 'PERCENTILE' in feature: #skip features that are percentiles (ordinal, shouldn't be zscored)\n",
    "        continue\n",
    "    else:\n",
    "        chems[feature] = scipy.stats.zscore(chems[feature], nan_policy = 'omit') # zscore\n",
    "chems['days_in_program'] = chems['days_in_program'].astype('float64')\n",
    "chems = chems.dropna(subset = 'days_in_program')\n",
    "chems_merged = pd.merge_asof( #merge scfa and chems by public client id on days in program\n",
    "    exchanges, chems, \n",
    "    by=\"public_client_id\", \n",
    "    on=\"days_in_program\", \n",
    "    direction=\"nearest\", \n",
    "    tolerance=30).dropna(subset=chem_features, how=\"all\")\n",
    "chem_features = chems.columns[chems.columns.isin(chem_features)]\n",
    "metadata = get_frozen_snapshot('chemistries_metadata').set_index('Name')['Display Name'].to_dict() #get display names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001efa4-92b5-4f72-ab86-a8f69b6d3a19",
   "metadata": {},
   "source": [
    "## Here we'll define our function for finding significantly associated markers. We need to rename some of the markers, due to Statsmodels constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa709f-26ff-4523-a7b1-cf6f0aa78faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hits(features, merged_df, marker, metadata): #enter the feature list, df, and scfa marker\n",
    "    df = pd.DataFrame(columns = {'feature':[],'p':[],'rho':[]}) #initialize df \n",
    "    for x in features: #need to replace special characters to use columns names in statsmodels.ols\n",
    "        x_fixed = x.replace('/','_')\n",
    "        x_fixed = x_fixed.replace(' ','_')\n",
    "        x_fixed = x_fixed.replace('-','_')\n",
    "        x_fixed = x_fixed.replace('(','')\n",
    "        x_fixed = x_fixed.replace(')','')\n",
    "        x_fixed = x_fixed.replace(',','')\n",
    "        merged_df.rename(columns={x:x_fixed}, inplace = True) #rename column with fixed name\n",
    "        if chems_merged[x_fixed].describe()['count'] == 0.0: #continue if only NaNs\n",
    "            continue\n",
    "        mod = statsmodels.formula.api.ols(formula = x_fixed+' ~'+marker+' + sex + age + vendor',\n",
    "                                          data = merged_df) #ordinary least squares\n",
    "        res = mod.fit() #fit to regression\n",
    "        new_feature = pd.DataFrame({'feature':[x_fixed],'display':metadata[x],'p':[res.pvalues[marker]],\n",
    "                                    'rho':[res.params[marker]]}) #pull out coefficients and pvalues\n",
    "        df = pd.concat([df,new_feature]) #add to output df\n",
    "    df = df.sort_values(by = 'p') #sort output df by pval\n",
    "    df.dropna(inplace = True) #drop na's\n",
    "    df.reset_index(inplace = True,drop = True)\n",
    "    df['p_corrected'] = statsmodels.stats.multitest.fdrcorrection(df['p'],\n",
    "                                                                  method = 'indep')[1] #fdr correct pvalues\n",
    "    df['measure'] = marker # add the name of the scfa marker being tested \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c190d95-960b-498c-bc6a-3156de8c0136",
   "metadata": {},
   "source": [
    "## Now we'll iterate this function across all our SCFAs to find significant hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cb664-da86-4f2f-bb7b-35f5c15c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_hits(chem_features, chems_merged, 'Propionate', metadata)\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Acetate', metadata)])\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Butyrate', metadata)])\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Total', metadata)])\n",
    "df = df[df.feature.isin(df[df['p_corrected']<0.05]['feature'].unique())] #significance only \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5400ea-0e18-4f32-970c-6b5339982003",
   "metadata": {},
   "source": [
    "## Now, plot significant hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159db34-b34e-4c0e-a0f9-8173e963860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = pd.pivot_table(df, columns = 'measure', \n",
    "                          index = 'display', values = 'rho') #pivot for heatmap values\n",
    "df_pivot = df_pivot[['Butyrate','Propionate','Acetate','Total']]\n",
    "pvals = pd.pivot_table(df, columns = 'measure',\n",
    "                       index = 'display', values = 'p_corrected') #pivot for heatmap annotations\n",
    "pvals = pvals[['Butyrate','Propionate','Acetate','Total']]\n",
    "pvals[pvals>0.05] = np.nan\n",
    "pvals[(pvals<=0.05)&(pvals>0.01)] = 100\n",
    "pvals[(pvals<=0.01)&(pvals>0.001)] = 200\n",
    "pvals[pvals<0.001] = 300\n",
    "pvals = pvals.replace(100,'*').replace(200,'**').replace(300,'***').replace(np.nan,'')\n",
    "\n",
    "sns.set(font_scale= 1.5)# set font\n",
    "f, ax = plt.subplots(figsize=(18,3)) #initialize plot\n",
    "cmap = sns.diverging_palette(230, 10, sep=20, as_cmap=True)\n",
    "ax = sns.heatmap(df_pivot.T, center = 0, cmap = cmap, annot = pvals.T, #make heatmap with annotations\n",
    "                 fmt='', annot_kws={'fontsize': 18, 'color':'white',\n",
    "                           'verticalalignment': 'center'})\n",
    "\n",
    "ax.set(xlabel = None)\n",
    "ax.set(ylabel = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef623b-aa9e-4350-b586-123637eafd71",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ac605-1d23-49f9-a5cb-e2d2d4012398",
   "metadata": {},
   "outputs": [],
   "source": [
    "chems_merged.to_csv('/proj/gibbons/nbohmann/exvivo/scfa_paper/arivale.csv')\n",
    "df.to_csv('/proj/gibbons/nbohmann/exvivo/scfa_paper/arivale_hits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
