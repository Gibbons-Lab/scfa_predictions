{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e763299-2834-41b6-ba4c-1a48c653e1f6",
   "metadata": {},
   "source": [
    "## We'll use this notebook to build and grow metabolic models for the Arivale cohort, and find associations between resulting SCFA production predictions and blood metabolites. Arivale data is not publically available, but is available to qualified researchers upon request given a data use agreement. Inquiries can be made at data-access@isbscience.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e69fa-fc46-4b29-b560-cab505c01189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import micom\n",
    "from plotnine import *\n",
    "import scipy\n",
    "import statsmodels\n",
    "\n",
    "## The ADI is an internal tool used for wrangling Arivale data \n",
    "from arivale_data_interface import *\n",
    "frozen_ss_path='/proj/arivale/snapshots/arivale_snapshot_ISB_2020-03-16_2156/'\n",
    "sn=list_snapshot_contents()\n",
    "def get_frozen_snapshot(ss_name, ss_path=frozen_ss_path):\n",
    "    \n",
    "    return get_snapshot(ss_name, path=ss_path)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e19a8d-a539-42cd-ae68-6b850b9dd507",
   "metadata": {},
   "source": [
    "## First we'll pull in our medium. We'll use a functionally complete medium representing a European diet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364682a-b912-4315-9216-e12b3b96dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the medium \n",
    "medium = pd.read_csv('../media/european.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bc9e2-16c2-419b-a06b-0b5d02b52a91",
   "metadata": {},
   "source": [
    "## Now we pull in our abundance data. ASV identifiers are present in a different file, which we'll map onto the taxonomy dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d3c3f-596d-4245-b501-866c957a98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the abundance data\n",
    "taxonomy = pd.read_csv('/proj/arivale/microbiome/16S_processed/asvs.csv')\n",
    "# And the associated ASV identifiers\n",
    "asv = pd.read_csv('/proj/arivale/microbiome/16S_processed/taxonomy_refseq.csv')\n",
    "# Pull the taxonomy info into a single colum\n",
    "asv['taxon'] = asv[['Kingdom','Phylum','Class','Order','Family','Genus']].apply(lambda row: \".\".join(\n",
    "    row.fillna(\"\").str.lower()), axis=1).to_frame()\n",
    "# Set the index as the id (hash) and turn into a dict\n",
    "asv = asv.set_index('id')['taxon'].to_dict()\n",
    "# Now map the ASV dict onto the taxonomy frame\n",
    "taxonomy['taxon'] = taxonomy['hash'].map(asv)\n",
    "# Create a genus column by splitting the taxonomy column\n",
    "taxonomy['genus'] = taxonomy['taxon'].str.split('.').str[-1].str.capitalize()\n",
    "# Replace empty classifications with NaNs and drop \n",
    "taxonomy['genus'] = taxonomy['genus'].replace('', np.nan)\n",
    "taxonomy = taxonomy.rename(columns = {'id':'sample_id',\n",
    "                                      'taxon':'id',\n",
    "                                      'count':'abundance'})\n",
    "taxonomy = taxonomy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590bd105-78f9-4cf9-975d-b12efdeb5120",
   "metadata": {},
   "source": [
    "## We'll also identify the model database we want to use to construct the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21968ebe-dfb6-4943-9fe7-2a47b7ed49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agora = ('../agora/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922993ba-0eda-4d2b-9edc-b3a263f00b09",
   "metadata": {},
   "source": [
    "## Now we can build our models, using the AGORA (version 1.03) database. We'll use an abundance cutoff of 0.001 for consistency with previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecb733-949b-4981-9325-41eab94f8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = micom.workflows.build(taxonomy, agora, '../models/arivale', \n",
    "                                 cutoff = 0.001, threads = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f4e0d-6864-4314-a296-7b75bf6d7be8",
   "metadata": {},
   "source": [
    "## Now we grow the models again, using the standard European diet and a tradeoff parameter of 0.7, for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650088a-d55c-4820-9b64-aee16d8a4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = micom.workflows.grow(manifest, '../models/arivale', medium, tradeoff = 0.7,threads = 20)\n",
    "exchanges = micom.measures.production_rates(growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79703ee4-5745-4b28-a747-56f44c2911af",
   "metadata": {},
   "source": [
    "## We can scale the flux by abundance and pull out SCFA exchanges, pivoting the table for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a4c50-7b5b-485a-8bd2-accfb502d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate SCFA production\n",
    "exchanges = exchanges[(exchanges['reaction'].str.startswith('EX_but(e)'))|\n",
    "                      (exchanges['reaction'].str.startswith('EX_ppa(e)'))|\n",
    "                      (exchanges['reaction'].str.startswith('EX_ac(e)'))]\n",
    "# Pivot the table\n",
    "exchanges = pd.pivot_table(exchanges, \n",
    "                           index = 'sample_id', \n",
    "                           columns = 'name', \n",
    "                           values = 'flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329541d-b424-4e6d-b7e6-a8fd1e1f5b7d",
   "metadata": {},
   "source": [
    "## Let's add a column for total SCFA production. We'll also fill in missing values and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f5913-8a41-4c58-92f5-e10b0de9271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for total SCFAs\n",
    "exchanges['Total'] = exchanges['but[e]'] + exchanges['ppa[e]'] + exchanges['ac[e]']\n",
    "# Add column for Butyrate and Propionate (both anti-inflammatory)\n",
    "exchanges['ButyrateAndPropionate'] = exchanges['but[e]'] + exchanges['ppa[e]']\n",
    "# Fill NaNs with zeros\n",
    "exchanges = exchanges.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ef727-95f8-405d-b85d-404cd39dafe4",
   "metadata": {},
   "source": [
    "## We'll need metadata to merge with the growth data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d0e01-39e9-4e8d-a064-659199160a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the metadata\n",
    "metadata = pd.read_csv('/proj/gibbons/arivale_16S/data/metadata.csv').rename(columns = {'id':'sample_id'})\n",
    "# Merge the exchanges with the metadata\n",
    "exchanges = pd.merge(exchanges, metadata, on = 'sample_id', how = 'inner')\n",
    "# Drop rows that don't have days in program data and sort \n",
    "exchanges = exchanges.dropna(subset = 'days_in_program').sort_values(by = 'days_in_program')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998289ab-809f-43a4-92be-b8acd0e0cf63",
   "metadata": {},
   "source": [
    "## Now we'll get our blood chemistry panel and z-score all the markers. Then we'll merge the chemistries with our predictions, using a tolerance of 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af772e-0f8b-42e1-bdb3-4db2bf587522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the chemistries data\n",
    "chems = get_frozen_snapshot('chemistries').sort_values(by = 'days_in_program')\n",
    "# Identify the names of features in the chemistries\n",
    "chem_features = chems.columns[12:]\n",
    "# For each feature, zscore the measurements, skipping any percentiles\n",
    "for feature in chem_features:\n",
    "    if 'PERCENTILE' in feature:\n",
    "        continue\n",
    "    else:\n",
    "        chems[feature] = scipy.stats.zscore(chems[feature], nan_policy = 'omit')\n",
    "# Convert days in program to a float\n",
    "chems['days_in_program'] = chems['days_in_program'].astype('float64')\n",
    "# Drop NaNs\n",
    "chems = chems.dropna(subset = 'days_in_program')\n",
    "# Merge the exchanges and chemistries based on days in program, finding points within 30 days of each other\n",
    "chems_merged = pd.merge_asof(\n",
    "    exchanges, chems, \n",
    "    by='public_client_id', \n",
    "    on='days_in_program', \n",
    "    direction='nearest', \n",
    "    tolerance=30).dropna(subset=chem_features, how='all')\n",
    "# Pull in chemistry metadata to apply full names to blood chemistries\n",
    "metadata = get_frozen_snapshot('chemistries_metadata').set_index('Name')['Display Name'].to_dict() #get display names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001efa4-92b5-4f72-ab86-a8f69b6d3a19",
   "metadata": {},
   "source": [
    "## Here we'll define our function for finding significantly associated markers. We need to rename some of the markers, due to Statsmodels formula constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa709f-26ff-4523-a7b1-cf6f0aa78faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the list of features, the dataframe, the SCFA of interest and the associated metadata\n",
    "def find_hits(features, merged_df, marker, metadata):\n",
    "    # Initialize a new dataframe to contain p values and beta coefficients for each feature\n",
    "    df = pd.DataFrame(columns = {'feature':[],'p':[],'beta hgfd':[]})\n",
    "    # Iterate through features\n",
    "    for x in features: \n",
    "        # Rename features for use in statsmodels OLS\n",
    "        x_fixed = x.replace('/','_')\n",
    "        x_fixed = x_fixed.replace(' ','_')\n",
    "        x_fixed = x_fixed.replace('-','_')\n",
    "        x_fixed = x_fixed.replace('(','')\n",
    "        x_fixed = x_fixed.replace(')','')\n",
    "        x_fixed = x_fixed.replace(',','')\n",
    "        merged_df.rename(columns={x:x_fixed}, inplace = True)\n",
    "        # If count is equal to zero, skip this feature\n",
    "        if chems_merged[x_fixed].describe()['count'] == 0.0:\n",
    "            continue\n",
    "        # Initialize regression model\n",
    "        mod = statsmodels.formula.api.ols(formula = x_fixed+' ~'+marker+' + sex + age + vendor',\n",
    "                                          data = merged_df) \n",
    "        # Fit to regression\n",
    "        res = mod.fit()\n",
    "        # Concatenate new feature to results dataframe\n",
    "        new_feature = pd.DataFrame({'feature':[x_fixed],'display':metadata[x],'p':[res.pvalues[marker]],\n",
    "                                    'rho':[res.params[marker]]})\n",
    "        df = pd.concat([df,new_feature]) #add to output df\n",
    "    # Reformat the dataframe\n",
    "    df = df.sort_values(by = 'p')\n",
    "    df.dropna(inplace = True)\n",
    "    df.reset_index(inplace = True,drop = True)\n",
    "    # FDR Correction of P values\n",
    "    df['p_corrected'] = statsmodels.stats.multitest.fdrcorrection(df['p'],\n",
    "                                                                  method = 'indep')[1] \n",
    "    # Add the name of the SCFA being used as a dependent variable\n",
    "    df['measure'] = marker\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c190d95-960b-498c-bc6a-3156de8c0136",
   "metadata": {},
   "source": [
    "## Now we'll iterate this function across all our SCFAs to find significant hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cb664-da86-4f2f-bb7b-35f5c15c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_hits(chem_features, chems_merged, 'Propionate', metadata)\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Acetate', metadata)])\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Butyrate', metadata)])\n",
    "df = pd.concat([df, find_hits(chem_features, chems_merged, 'Total', metadata)])\n",
    "df = df[df.feature.isin(df[df['p_corrected']<0.05]['feature'].unique())] #significance only \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8b690-4cb9-49ae-ba72-1f81eea20a2b",
   "metadata": {},
   "source": [
    "## We need to replace the pvalues with a symbolic representation. This function will do that when applied to a dataframe of pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f41a05-e75e-4fb8-82a4-41f5eaaa982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue_stars(val):\n",
    "    if val < 0.001:\n",
    "        return '***'\n",
    "    elif val < 0.01:\n",
    "        return '**'\n",
    "    elif val < 0.05: \n",
    "        return '*'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5400ea-0e18-4f32-970c-6b5339982003",
   "metadata": {},
   "source": [
    "## Now, build the pivot tables and plot the results in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159db34-b34e-4c0e-a0f9-8173e963860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table\n",
    "df_pivot = pd.pivot_table(df, columns = 'measure', \n",
    "                          index = 'display', values = 'rho')\n",
    "# Reorder the columns\n",
    "df_pivot = df_pivot[['Butyrate','Propionate','Acetate','Total']]\n",
    "# Build a new pivoted table of p values \n",
    "pvals = pd.pivot_table(df, columns = 'measure',\n",
    "                       index = 'display', values = 'p_corrected') #pivot for heatmap annotations\n",
    "# Reorder the columns\n",
    "pvals = pvals[['Butyrate','Propionate','Acetate','Total']]\n",
    "pvals = pvals.applymap(pvalue_stars)\n",
    "\n",
    "# Build the heatmap\n",
    "sns.set(font_scale= 1.5)# set font\n",
    "f, ax = plt.subplots(figsize=(5,9)) #initialize plot\n",
    "cmap = sns.diverging_palette(230, 10, sep=20, as_cmap=True)\n",
    "ax = sns.heatmap(df_pivot, center = 0, cmap = cmap, annot = pvals, #make heatmap with annotations\n",
    "                 fmt='', annot_kws={'fontsize': 18, 'color':'white',\n",
    "                           'verticalalignment': 'center'})\n",
    "\n",
    "ax.set(xlabel = None)\n",
    "ax.set(ylabel = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef623b-aa9e-4350-b586-123637eafd71",
   "metadata": {},
   "source": [
    "## Save results to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ac605-1d23-49f9-a5cb-e2d2d4012398",
   "metadata": {},
   "outputs": [],
   "source": [
    "chems_merged.to_csv('../data/arivale_exchanges.csv')\n",
    "df.to_csv('../data/arivale_hits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
