{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca54eea-e19b-4b03-a1ad-0d668e458e0d",
   "metadata": {},
   "source": [
    "## In this notebook, we'll investigate how to use MICOM microbial community metabolic modeling to design and test pre- and probiotic interventions aimed at augmenting butyrate production from the gut microbiome. We'll utilize the models we built in the arivale.ipynb notebook for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5163abcd-c6bd-4a89-8ee7-7941bf4c059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import micom \n",
    "import micom.measures\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import statsmodels\n",
    "from plotnine import *\n",
    "\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9fed4-a719-468a-b9da-c3b6319a39a1",
   "metadata": {},
   "source": [
    "## First, we grow all our Arivale models on the standard European diet, which was completed using the medium_construction.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c16bfe-9a4a-45d1-bcb7-bfe33b955da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the manifest\n",
    "manifest = pd.read_csv('../models/arivale/manifest.csv',index_col = 0)\n",
    "# Load the standard European medium\n",
    "EU_medium = pd.read_csv('../media/european.csv')\n",
    "# Grow the models in MICOM\n",
    "growth = micom.workflows.grow(manifest, model_folder='../models/arivale',\n",
    "                                 medium = EU_medium, tradeoff = 0.7, strategy = 'none',threads = 20,presolve = True)\n",
    "# Calculate production flux\n",
    "exchanges = micom.measures.production_rates(growth)\n",
    "# Isolate butyrate production\n",
    "european = exchanges[exchanges['reaction'].str.startswith('EX_but(e)')].reset_index(drop = True)\n",
    "# Add a column indicating the medium that was used\n",
    "european['diet'] = 'EU'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962073f4-143c-47a3-a7e4-238d02aa614c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next, we grow the models on the high fiber diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd93644-1777-465e-a4f3-8229825c0f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load up the manifest\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m manifest \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/arivale/manifest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the high fiber medium\u001b[39;00m\n\u001b[1;32m      4\u001b[0m HF_medium \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../media/highfiber.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load up the manifest\n",
    "manifest = pd.read_csv('../models/arivale/manifest.csv',index_col = 0)\n",
    "# Load the high fiber medium\n",
    "HF_medium = pd.read_csv('../media/highfiber.csv')\n",
    "# Grow the models in MICOM\n",
    "growth = micom.workflows.grow(manifest, model_folder='../models/arivale',\n",
    "                                 medium = HF_medium, tradeoff = 0.7, strategy = 'none',threads = 20,presolve = True)\n",
    "# Calculate production flux\n",
    "exchanges = micom.measures.production_rates(growth)\n",
    "# Isolate butyrate production\n",
    "high_fiber = exchanges[exchanges['reaction'].str.startswith('EX_but(e)')].reset_index(drop = True)\n",
    "# Add a column indicating the medium that was used\n",
    "high_fiber['diet'] = 'High Fiber'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08350f-7d28-4e8c-b986-11aecab0f8b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lets merge these dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85f9ec-f233-45da-b95e-e98ec86d7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "butyrate = pd.concat([butyrate, high_fiber])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a04ac-b2e1-4436-ab95-21c122afe0e9",
   "metadata": {},
   "source": [
    "## Before we move forward, let's define a function that will calculate percentage change between two diets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711f027-85b6-47e2-a577-cda27bcf864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_change(col1,col2):\n",
    "    return ((col2 - col1) / col1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fc32c-1d96-4f5c-996e-2c3281550901",
   "metadata": {},
   "source": [
    "## Calculate the percentage change of butyrate production in each sample between dietary contexts, and define individuals who are 'non-responders' or 'regressors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad01ff-3fbc-471c-bca7-c8ae49a64eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table \n",
    "butyrate_pvt = pd.pivot_table(butyrate,index = 'sample_id',columns = 'diet', values = 'flux')\n",
    "# Calculate percentage change in butyrate production from the EU diet to the high fiber diet\n",
    "butyrate_pvt['change'] = percentage_change(butyrate_pvt['EU'],butyrate_pvt['High Fiber'])\n",
    "# Define non-responders (low butyrate production in both contexts)\n",
    "nonresponders = butyrate_pvt[(butyrate_pvt['EU']<10)&(butyrate_pvt['change']<20)]\n",
    "# Define regressors (high butyrate on EU medium, decrease on high fiber) \n",
    "regressors = butyrate_pvt[(butyrate_pvt['EU']>19.9)&(butyrate_pvt['change']<0)]\n",
    "# Define the bounds of butyrate production in each of these groups\n",
    "box_nonresponders = [nonresponders[['EU','High Fiber']].min().min(), nonresponders[['EU','High Fiber']].max().max()]\n",
    "box_regressors = [regressors[['EU','High Fiber']].min().min(), regressors[['EU','High Fiber']].max().max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6784852-d85b-427c-abbb-8710395db9c7",
   "metadata": {},
   "source": [
    "## Make a histogram showing the butyrate production profiles of the population on each diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641a95a-59b0-4885-96ad-a7c6e7ab7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plt = (ggplot(\n",
    "    butyrate,aes(x = 'but'))\n",
    "    +annotate(geom_rect, xmin=box_nonresponders[0], xmax=box_nonresponders[1], ymin=0, ymax=float('inf'),\n",
    "              fill = 'darkgreen', alpha=0.3)\n",
    "    +annotate(geom_rect, xmin=box_regressors[0], xmax=box_regressors[1], ymin=0, ymax=float('inf'),\n",
    "              fill = 'orange', alpha=0.3)\n",
    "    +geom_density(aes(fill = 'diet'))\n",
    "    +labs(x = 'Butyrate Production ($\\dfrac{mmol}{gDW*h}$)',y = 'Fraction',\n",
    "          color = 'Butyrate Production Quantile, EU Diet')\n",
    "    +scale_fill_discrete(name = 'Diet', labels = ['European','High Fiber'])\n",
    "    +theme(text = element_text(size=20),\n",
    "       panel_background=element_rect(fill = \"white\", colour = \"white\",size = 0.5, linetype = \"solid\"),\n",
    "       panel_grid=element_blank(),\n",
    "       axis_line = element_line(size = 2, linetype = \"solid\", colour = \"black\"),\n",
    "       legend_title=element_blank(), legend_position='right'))\n",
    "hist_plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668924a7-4bb3-427f-8c25-ac18cca31d11",
   "metadata": {},
   "source": [
    "## Before testing interventions on the subsets, we'll pull in all our dietary interventions. These include an average European diet, a high-fiber diet, and each of those two diets supplemented with inulin or pectin (neither present in the original high-fiber diet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ebb42-06a8-4555-a445-689865ef55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard European diet \n",
    "eu_diet = (pd.read_csv('/proj/gibbons/nbohmann/exvivo/diets/western_completed.csv').set_index('reaction'))\n",
    "# High Fiber diet\n",
    "hf_diet = (pd.read_csv('/proj/gibbons/nbohmann/exvivo/diets/highfiber_completed.csv')\n",
    "           .set_index('reaction'))\n",
    "# European diet with pectin suplementation\n",
    "eu_diet_pect= pd.concat([eu_diet, pd.DataFrame(index = ['EX_pect_m'],data = {'flux': [0.75], 'dilution':[1.0],\n",
    "                                                                             'metabolite':['pect_m']})])\n",
    "# European diet with inulin suplementation\n",
    "eu_diet_inulin = pd.concat([eu_diet, pd.DataFrame(index = ['EX_inulin_m'],data = {'flux': [10.5], 'dilution':[1.0],\n",
    "                                                                             'metabolite':['inulin_m']})])\n",
    "# High Fiber diet with pectin suplementation\n",
    "hf_diet_pect= pd.concat([hf_diet, pd.DataFrame(index = ['EX_pect_m'],data = {'flux': [0.75], 'dilution':[1.0],\n",
    "                                                                             'metabolite':['pect_m']})])\n",
    "# High Fiber diet with inulin supplementation\n",
    "hf_diet_inulin = pd.concat([hf_diet, pd.DataFrame(index = ['EX_inulin_m'],data = {'flux': [10.5], 'dilution':[1.0],\n",
    "                                                                             'metabolite':['inulin_m']})])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f37904-8f88-4c30-91c8-8712c940da51",
   "metadata": {},
   "source": [
    "## Let's define implementation of interventions here - we can iterate across these with each intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6acab3-8eda-429f-a9be-3b598791ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the name of the community model, and the intervention\n",
    "def diet_intervention(com_name, diet):\n",
    "    # Load file\n",
    "    com = micom.load_pickle(com_name+'.pickle')\n",
    "    # Apply intervention medium\n",
    "    com.medium = diet.flux\n",
    "    # Grow the model using the MICOM single-model API \n",
    "    growth = com.cooperative_tradeoff(fraction = 0.7,fluxes = True)\n",
    "    # Collect fluxes \n",
    "    res = growth.fluxes.mul(growth.members.abundance, axis = 0)\n",
    "    # Isolate production flux\n",
    "    res = res[res['EX_but(e)']>0]\n",
    "    # Sum production fluxes together\n",
    "    sol = res['EX_but(e)'].sum()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad622efe-71ec-4fc8-866a-42087d218e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>genus</th>\n",
       "      <th>abundance</th>\n",
       "      <th>taxon</th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bakjsbdf</td>\n",
       "      <td>Faecalibacterium</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Faecalibacterium</td>\n",
       "      <td>Faecalibacterium</td>\n",
       "      <td>../agora/data/Faecalibacterium.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id             genus  abundance             taxon                id  \\\n",
       "0  bakjsbdf  Faecalibacterium        0.1  Faecalibacterium  Faecalibacterium   \n",
       "\n",
       "                                  file  \n",
       "0  ../agora/data/Faecalibacterium.json  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'sample_id':['bakjsbdf'], \n",
    "              'genus': ['Faecalibacterium'], \n",
    "              'abundance':[0.10], \n",
    "              'taxon':['Faecalibacterium'],\n",
    "              'id':['Faecalibacterium'],\n",
    "              'file':['../agora/data/Faecalibacterium.json']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2e831-a292-4c00-9a0a-21cf1cdeab01",
   "metadata": {},
   "source": [
    "## Let's also define our probiotic intervention, which we can apply to different diets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3c27ae-f488-4ce2-a7bc-b046a301569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the name of the community model and the diet \n",
    "def probiotic_intervention(com_name, diet): \n",
    "    # Load file\n",
    "    com = micom.load_pickle(com_name+'.pickle')\n",
    "    # Remove any Faecalibacterium already in the model\n",
    "    taxonomy = com.taxonomy[~com.taxonomy.index.str.contains('Faecalibacterium')]\n",
    "    # Scale abundance to 90% of original \n",
    "    taxonomy['abundance'] = taxonomy['abundance']/(10/9)\n",
    "    # Build a new taxonomy table \n",
    "    taxonomy = pd.concat([taxonomy,pd.DataFrame({'sample_id':['bakjsbdf'], \n",
    "              'genus': ['Faecalibacterium'], \n",
    "              'abundance':[0.10], \n",
    "              'taxon':['Faecalibacterium'],\n",
    "              'id':['Faecalibacterium'],\n",
    "              'file':['../agora/data/Faecalibacterium.json']})])\n",
    "    # Construct a new community with the table\n",
    "    probiotic_com = micom.Community(taxonomy)\n",
    "    # Apply a diet \n",
    "    probiotic_com.medium = diet.flux\n",
    "    # Grow the model with the single model API\n",
    "    growth_probiotic = probiotic_com.cooperative_tradeoff(fraction = 0.7,fluxes = True)\n",
    "    # Calculate flux\n",
    "    res = growth_probiotic.fluxes.mul(growth_probiotic.members.abundance, axis = 0)\n",
    "    # Isolate production flux\n",
    "    res = res[res['EX_but(e)']>0]\n",
    "    # Sum butyrate production \n",
    "    sol = res['EX_but(e)'].sum()\n",
    "    return res "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8762e3b-77a1-4ca6-8087-059b78fe1d07",
   "metadata": {},
   "source": [
    "## Now we iterate across all the interventions with our samples. We'll do this twice, with the list \"samples\" (non-responders) and \"samples2\" (regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a13286-ddf2-4608-bb35-94f99c9ce418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataframe for holding results of interventions for regressors\n",
    "intRegressors = pd.DataFrame()\n",
    "# Iterate through each sample and apply interventions\n",
    "for com_name in regressors.index:\n",
    "    sol1 = diet_intervention(com_name, eu_diet)\n",
    "    sol2 = diet_intervention(com_name, hf_diet)\n",
    "    sol3 = diet_intervention(com_name, eu_diet_pect)\n",
    "    sol4 = diet_intervention(com_name, hf_diet_pect)\n",
    "    sol5 = diet_intervention(com_name, eu_diet_inulin)\n",
    "    sol6 = diet_intervention(com_name, hf_diet_inulin)\n",
    "    sol7 = probiotic_intervention(com_name, eu_diet)\n",
    "    sol8 = probiotic_intervention(com_name, hf_diet)\n",
    "    # Create a dataframe of results\n",
    "    to_add = pd.DataFrame(index = [com_name], data = {'Euro': sol1, 'High-Fiber':sol2,\n",
    "                                                      'Euro + Pectin': sol3, 'HF + Pectin': sol4, \n",
    "                                                      'Euro + Inulin':sol5, 'HF + Inulin':sol6,\n",
    "                                                      'Euro + Probiotic':sol7, 'HF + Probiotic': sol8})\n",
    "    # Concatenate with dataframe\n",
    "    intRegressors = pd.concat([intRegressors, to_add])\n",
    "    \n",
    "# Construct a dataframe for holding results of interventions for non-responders   \n",
    "intNonResponders = pd.DataFrame()\n",
    "# Iterate through each sample and apply interventions\n",
    "for com_name in nonresponders.index:\n",
    "    sol1 = diet_intervention(com_name, eu_diet)\n",
    "    sol2 = diet_intervention(com_name, hf_diet)\n",
    "    sol3 = diet_intervention(com_name, eu_diet_pect)\n",
    "    sol4 = diet_intervention(com_name, hf_diet_pect)\n",
    "    sol5 = diet_intervention(com_name, eu_diet_inulin)\n",
    "    sol6 = diet_intervention(com_name, hf_diet_inulin)\n",
    "    sol7 = probiotic_intervention(com_name, eu_diet)\n",
    "    sol8 = probiotic_intervention(com_name, hf_diet)\n",
    "    # Create a dataframe of results\n",
    "    to_add = pd.DataFrame(index = [com_name], data = {'Euro': sol1, 'High-Fiber':sol2,\n",
    "                                                      'Euro + Pectin': sol3, 'HF + Pectin': sol4, \n",
    "                                                      'Euro + Inulin':sol5, 'HF + Inulin':sol6,\n",
    "                                                      'Euro + Probiotic':sol7, 'HF + Probiotic': sol8})\n",
    "    # Concatenate with dataframe\n",
    "    intNonresponders = pd.concat([intNonresponders, to_add])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53ac2e-cbbd-4608-be35-397d197bdae4",
   "metadata": {},
   "source": [
    "## We'll concatenate our results, making sure to remember which set each sample comes from \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d6cae9-7775-429a-9834-bcccc3bf2fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intRegressors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Rename index to group name\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m intRegressors\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m ([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressors\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mintRegressors\u001b[49m)\n\u001b[1;32m      3\u001b[0m intNonresponders\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m ([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-responders\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(intNonresponders)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Concatenate\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intRegressors' is not defined"
     ]
    }
   ],
   "source": [
    "# Rename index to group name\n",
    "intRegressors.index = (['regressors'])*len(intRegressors)\n",
    "intNonresponders.index = (['non-responders'])*len(intNonresponders)\n",
    "# Concatenate\n",
    "intervention = pd.concat([intRegressors, intNonresponders])\n",
    "# Sort by intervention result\n",
    "intervention = intervention.sort_values(by = ['Euro','High-Fiber','Euro + Pectin', 'HF + Pectin',\n",
    "                                          'Euro + Inulin', 'HF + Inulin','Euro + Probiotic', 'HF + Probiotic'])\n",
    "# Create a new dataframe with the maximum value for each sample\n",
    "max_list = intervention.rename(columns = {'Euro':0,'High-Fiber':1,'Euro + Pectin':2, 'HF + Pectin':3,\n",
    "                                          'Euro + Inulin':4, 'HF + Inulin':5,'Euro + Probiotic':6, 'HF + Probiotic':7}\n",
    "                              ).idxmax(axis = 'columns')\n",
    "intervention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd208f-9320-40ed-a4a1-0073e1bfd4eb",
   "metadata": {},
   "source": [
    "## Now we make a heatmap with black rectangles around the optimal intervention for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc899a9-008e-463f-b666-415c42a6c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "lut = {'Non-Responders':'#b2d0b1', 'Regressors':'#fee3b2'}\n",
    "row_colors = intervention.index.map(lut)\n",
    "\n",
    "sns.set(font_scale= 1.5)# set font\n",
    "cmap = sns.diverging_palette(230, 200, sep=20, as_cmap=True)\n",
    "ax = sns.clustermap(intervention.T,cmap = 'Reds',figsize = (20,10), #make heatmap with annotations\n",
    "                 fmt='',col_colors = row_colors, col_cluster = False, row_cluster = False,\n",
    "                    annot_kws={'fontsize': 18, 'color':'white','verticalalignment': 'center'})\n",
    "\n",
    "ax.ax_cbar.set_ylabel(\"Butyrate($\\dfrac{mmol}{gDW*h}$)\",size=20)\n",
    "ax.ax_cbar.set_position((.1, .2, .03, .5))\n",
    "for x in range(len(max_list)):\n",
    "    ax.ax_heatmap.add_patch(Rectangle((x,max_list[x]), 1, 1, fill=False, edgecolor='black', lw=3))\n",
    "\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae5e64-f2d4-4c34-865e-eeb0f45eb2b0",
   "metadata": {},
   "source": [
    "## Save these reuslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8fc3e-8564-4d95-9247-bddfdafc3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "intRegressors.to_csv('/o.csv')\n",
    "intNonresponders.to_csv('/proj/gibbons/nbohmann/exvivo/scfa_paper/intervention2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
